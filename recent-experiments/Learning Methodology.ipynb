{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67c3cfc5",
   "metadata": {},
   "source": [
    "## Learning Methodology\n",
    "<h4>Team Twin AI</h4>\n",
    "<h4><b>Overview</b></h4>\n",
    "\n",
    "This is the Machine Learning component of our solution to the FormulaAI Hack 2022 Competition. The workflow for this notebook is outlined as follows:\n",
    "- Standardisation and Pipelines\n",
    "- Model Experimentations I: Classification\n",
    "- Model Experimentations II: Regression\n",
    "- Evaluation and Predictions\n",
    "- Leaderboard: Rankings the Challenger Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3ab394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None, 'display.max_rows', 100)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "import deepchecks as dc\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import GenericUnivariateSelect\n",
    "from sklearn.preprocessing import scale,StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "#from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "#from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "#from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "#from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004a388a",
   "metadata": {},
   "source": [
    "#### <i>Read the data<i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efa40761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(534055, 14)\n",
      "(534055, 14)\n"
     ]
    }
   ],
   "source": [
    "#final_data_weather = pd.read_csv('final_data_weather.csv')\n",
    "#final_data_weather.drop('Unnamed: 0', axis =1, inplace = True)\n",
    "#print(final_data_weather.shape)\n",
    "#\n",
    "#final_data_rain = pd.read_csv('final_data_rain.csv')\n",
    "#final_data_rain.drop('Unnamed: 0', axis =1, inplace = True)\n",
    "#print(final_data_rain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9a000ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(534055, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M_SESSION_UID</th>\n",
       "      <th>M_SESSION_TIME</th>\n",
       "      <th>M_FRAME_IDENTIFIER</th>\n",
       "      <th>M_PLAYER_CAR_INDEX</th>\n",
       "      <th>M_SESSION_LINK_IDENTIFIER</th>\n",
       "      <th>M_TRACK_TEMPERATURE</th>\n",
       "      <th>M_TRACK_LENGTH</th>\n",
       "      <th>M_AIR_TEMPERATURE</th>\n",
       "      <th>M_TRACK_ID</th>\n",
       "      <th>M_TIME_OFFSET</th>\n",
       "      <th>M_RAIN_PERCENTAGE</th>\n",
       "      <th>M_AI_DIFFICULTY</th>\n",
       "      <th>M_NUM_MARSHAL_ZONES</th>\n",
       "      <th>M_SESSION_TIME_SPENT</th>\n",
       "      <th>M_WEATHER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.106082e+16</td>\n",
       "      <td>28.86</td>\n",
       "      <td>624</td>\n",
       "      <td>19</td>\n",
       "      <td>2184232491</td>\n",
       "      <td>33</td>\n",
       "      <td>4650</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>90</td>\n",
       "      <td>16.0</td>\n",
       "      <td>788</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.106082e+16</td>\n",
       "      <td>28.86</td>\n",
       "      <td>624</td>\n",
       "      <td>19</td>\n",
       "      <td>2184232491</td>\n",
       "      <td>33</td>\n",
       "      <td>4650</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>90</td>\n",
       "      <td>16.0</td>\n",
       "      <td>788</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   M_SESSION_UID  M_SESSION_TIME  M_FRAME_IDENTIFIER  M_PLAYER_CAR_INDEX  \\\n",
       "0   2.106082e+16           28.86                 624                  19   \n",
       "1   2.106082e+16           28.86                 624                  19   \n",
       "\n",
       "   M_SESSION_LINK_IDENTIFIER  M_TRACK_TEMPERATURE  M_TRACK_LENGTH  \\\n",
       "0                 2184232491                   33            4650   \n",
       "1                 2184232491                   33            4650   \n",
       "\n",
       "   M_AIR_TEMPERATURE  M_TRACK_ID  M_TIME_OFFSET  M_RAIN_PERCENTAGE  \\\n",
       "0                 25          28            5.0                3.0   \n",
       "1                 25          28            5.0                3.0   \n",
       "\n",
       "   M_AI_DIFFICULTY  M_NUM_MARSHAL_ZONES  M_SESSION_TIME_SPENT  M_WEATHER  \n",
       "0               90                 16.0                   788          0  \n",
       "1               90                 16.0                   788          0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data_weather = pd.read_csv('final_data_weather.csv', index_col = False)\n",
    "print(final_data_weather.shape)\n",
    "final_data_weather.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33891331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(534055, 14)\n",
      "(534055, 14)\n"
     ]
    }
   ],
   "source": [
    "weather_X = final_data_weather.drop('M_WEATHER', axis=1)\n",
    "weather_y = final_data_weather['M_WEATHER']\n",
    "\n",
    "rain_X = final_data_weather.drop('M_RAIN_PERCENTAGE', axis=1)\n",
    "rain_y = final_data_weather['M_RAIN_PERCENTAGE']\n",
    "\n",
    "print(weather_X.shape)\n",
    "print(rain_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afddb158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b66a9f54",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h4><b>1. Cross-Validation, Standardisation and Pipelines</b></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286173f6",
   "metadata": {},
   "source": [
    "***Creating train, test and validation sets***\n",
    "    \n",
    "We first split our data into train and test sets. The test set is our holdout set and will not be unlocked until the end of each of the 2 sequences of experiments for classification and regression, respectively. The validation set will be split out of the train data and will be used for primary evaluation and to compute cross validation scores in each of our experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb54b219",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(weather_X, weather_y, test_size=.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46ea546",
   "metadata": {},
   "source": [
    "Considering the huge class imbalance in the weather target, ***we will implement repeated k-fold cross validation to further split our train data***. For our classification experiments, we will use ***repeated stratified k-fold cross validation***. We choose the value of 10 for *k* as this value has been shown empirically to yield test error rate estimates that suffer neither from excessively high bias nor from very high variance. In other words, we are choosing *k = 10* to achieve reasonable bias-variance trade-off in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f05f7910",
   "metadata": {},
   "outputs": [],
   "source": [
    "skfold = RepeatedStratifiedKFold(n_splits=10, n_repeats = 2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed6e164",
   "metadata": {},
   "source": [
    "Now, we will define a helper function that we will use for all our classification experiments. This function will also be associated with a class to return validation scores for each experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d0a8f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierScores:\n",
    "    def __init__(self):\n",
    "        self.accuracy = mean_accuracy\n",
    "        self.logloss = mean_loss\n",
    "\n",
    "def training(X_train, y_train, model):\n",
    "\n",
    "    fold_no = 1    \n",
    "    n_scores, log_scores = [],[]\n",
    "    for train_index, val_index in skfold.split(X_train, y_train):\n",
    "        # select rows\n",
    "        train_X, val_X = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "        train_y, val_y = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "        model.fit(train_X, train_y)\n",
    "        n_scores.append(model.score(val_X, val_y))\n",
    "        log_scores.append(log_loss(val_y, model.predict_proba(val_X), labels = [0,1,2]))\n",
    "        print('For Fold {}, the Accuracy is {},'.format(str(fold_no), n_scores[fold_no - 1]), \n",
    "              'and the LogLoss is', log_scores[fold_no - 1])\n",
    "\n",
    "        fold_no += 1\n",
    "        \n",
    "    mean_accuracy, std_accuracy = np.mean(n_scores), np.std(n_scores)\n",
    "    mean_loss, std_loss = np.mean(log_scores), np.std(log_scores)\n",
    "    \n",
    "    print('\\n======================================')\n",
    "    print('Average Accuracy and LogLoss:')\n",
    "\n",
    "    return model, ClassifierScores()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592c4b1f",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "***To avoid information leakage from our test data into the models we want to train, we will make use of pipelines in most of our experiments.***\n",
    "\n",
    "We define a pipeline construct below that implements standardisation on our data to make it Gaussian distributed, then fits a model on the standardised data. For experiments on just raw features, we will implement a pipeline without Standard Scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bd315cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_pipe(model_name, x_train, y_train):\n",
    "    \"\"\"\n",
    "    This function standardises the data to make it Gaussian distributed, then applies a \n",
    "    pipeline construct to fit a model on the standardised data\n",
    "    \"\"\"\n",
    "    trans = StandardScaler()\n",
    "    model_pipeline = Pipeline([('scaler', trans), ('model', model_name)])\n",
    "    \n",
    "    training(x_train, y_train, model_pipeline)\n",
    "    \n",
    "    return model_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440c4d6f",
   "metadata": {},
   "source": [
    "We will experiment with various models with and without standardisation and see how they perform. But before we proceed, let's see what our data looks like when standardised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44308161",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M_SESSION_UID</th>\n",
       "      <th>M_SESSION_TIME</th>\n",
       "      <th>M_FRAME_IDENTIFIER</th>\n",
       "      <th>M_PLAYER_CAR_INDEX</th>\n",
       "      <th>M_SESSION_LINK_IDENTIFIER</th>\n",
       "      <th>M_TRACK_TEMPERATURE</th>\n",
       "      <th>M_TRACK_LENGTH</th>\n",
       "      <th>M_AIR_TEMPERATURE</th>\n",
       "      <th>M_TRACK_ID</th>\n",
       "      <th>M_TIME_OFFSET</th>\n",
       "      <th>M_RAIN_PERCENTAGE</th>\n",
       "      <th>M_AI_DIFFICULTY</th>\n",
       "      <th>M_NUM_MARSHAL_ZONES</th>\n",
       "      <th>M_SESSION_TIME_SPENT</th>\n",
       "      <th>M_WEATHER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.941930</td>\n",
       "      <td>-0.907981</td>\n",
       "      <td>-0.958823</td>\n",
       "      <td>0.481238</td>\n",
       "      <td>-0.834546</td>\n",
       "      <td>-0.185343</td>\n",
       "      <td>-1.821453</td>\n",
       "      <td>-0.390822</td>\n",
       "      <td>1.745594</td>\n",
       "      <td>-0.918268</td>\n",
       "      <td>-0.320525</td>\n",
       "      <td>1.701675</td>\n",
       "      <td>-1.353735</td>\n",
       "      <td>-0.227546</td>\n",
       "      <td>-0.627758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.941930</td>\n",
       "      <td>-0.907981</td>\n",
       "      <td>-0.958823</td>\n",
       "      <td>0.481238</td>\n",
       "      <td>-0.834546</td>\n",
       "      <td>-0.185343</td>\n",
       "      <td>-1.821453</td>\n",
       "      <td>-0.390822</td>\n",
       "      <td>1.745594</td>\n",
       "      <td>-0.918268</td>\n",
       "      <td>-0.320525</td>\n",
       "      <td>1.701675</td>\n",
       "      <td>-1.353735</td>\n",
       "      <td>-0.227546</td>\n",
       "      <td>-0.627758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.941930</td>\n",
       "      <td>-0.907981</td>\n",
       "      <td>-0.958823</td>\n",
       "      <td>0.481238</td>\n",
       "      <td>-0.834546</td>\n",
       "      <td>-0.185343</td>\n",
       "      <td>-1.821453</td>\n",
       "      <td>-0.390822</td>\n",
       "      <td>1.745594</td>\n",
       "      <td>-0.723403</td>\n",
       "      <td>-0.320525</td>\n",
       "      <td>1.701675</td>\n",
       "      <td>-1.353735</td>\n",
       "      <td>-0.227546</td>\n",
       "      <td>-0.627758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.941930</td>\n",
       "      <td>-0.907981</td>\n",
       "      <td>-0.958823</td>\n",
       "      <td>0.481238</td>\n",
       "      <td>-0.834546</td>\n",
       "      <td>-0.185343</td>\n",
       "      <td>-1.821453</td>\n",
       "      <td>-0.390822</td>\n",
       "      <td>1.745594</td>\n",
       "      <td>-0.723403</td>\n",
       "      <td>-0.320525</td>\n",
       "      <td>1.701675</td>\n",
       "      <td>-1.353735</td>\n",
       "      <td>-0.227546</td>\n",
       "      <td>-0.627758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.941930</td>\n",
       "      <td>-0.907981</td>\n",
       "      <td>-0.958823</td>\n",
       "      <td>0.481238</td>\n",
       "      <td>-0.834546</td>\n",
       "      <td>-0.185343</td>\n",
       "      <td>-1.821453</td>\n",
       "      <td>-0.390822</td>\n",
       "      <td>1.745594</td>\n",
       "      <td>-0.528538</td>\n",
       "      <td>-0.320525</td>\n",
       "      <td>1.701675</td>\n",
       "      <td>-1.353735</td>\n",
       "      <td>-0.227546</td>\n",
       "      <td>-0.627758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534050</th>\n",
       "      <td>2.209103</td>\n",
       "      <td>-0.928847</td>\n",
       "      <td>-0.981442</td>\n",
       "      <td>-2.199539</td>\n",
       "      <td>1.230293</td>\n",
       "      <td>-1.901298</td>\n",
       "      <td>0.544278</td>\n",
       "      <td>-2.205470</td>\n",
       "      <td>-0.654983</td>\n",
       "      <td>-0.723403</td>\n",
       "      <td>1.130695</td>\n",
       "      <td>-0.517774</td>\n",
       "      <td>2.862515</td>\n",
       "      <td>-1.070066</td>\n",
       "      <td>1.372537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534051</th>\n",
       "      <td>2.209103</td>\n",
       "      <td>-0.928847</td>\n",
       "      <td>-0.981442</td>\n",
       "      <td>-2.199539</td>\n",
       "      <td>1.230293</td>\n",
       "      <td>-1.901298</td>\n",
       "      <td>0.544278</td>\n",
       "      <td>-2.205470</td>\n",
       "      <td>-0.654983</td>\n",
       "      <td>-0.528538</td>\n",
       "      <td>0.767890</td>\n",
       "      <td>-0.517774</td>\n",
       "      <td>2.862515</td>\n",
       "      <td>-1.070066</td>\n",
       "      <td>1.372537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534052</th>\n",
       "      <td>2.209103</td>\n",
       "      <td>-0.928847</td>\n",
       "      <td>-0.981442</td>\n",
       "      <td>-2.199539</td>\n",
       "      <td>1.230293</td>\n",
       "      <td>-1.901298</td>\n",
       "      <td>0.544278</td>\n",
       "      <td>-2.205470</td>\n",
       "      <td>-0.654983</td>\n",
       "      <td>0.056057</td>\n",
       "      <td>-0.139123</td>\n",
       "      <td>-0.517774</td>\n",
       "      <td>2.862515</td>\n",
       "      <td>-1.070066</td>\n",
       "      <td>1.372537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534053</th>\n",
       "      <td>2.209103</td>\n",
       "      <td>-0.928847</td>\n",
       "      <td>-0.981442</td>\n",
       "      <td>-2.199539</td>\n",
       "      <td>1.230293</td>\n",
       "      <td>-1.901298</td>\n",
       "      <td>0.544278</td>\n",
       "      <td>-2.205470</td>\n",
       "      <td>-0.654983</td>\n",
       "      <td>0.640653</td>\n",
       "      <td>-0.139123</td>\n",
       "      <td>-0.517774</td>\n",
       "      <td>2.862515</td>\n",
       "      <td>-1.070066</td>\n",
       "      <td>1.372537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534054</th>\n",
       "      <td>2.209103</td>\n",
       "      <td>-0.928847</td>\n",
       "      <td>-0.981442</td>\n",
       "      <td>-2.199539</td>\n",
       "      <td>1.230293</td>\n",
       "      <td>-1.901298</td>\n",
       "      <td>0.544278</td>\n",
       "      <td>-2.205470</td>\n",
       "      <td>-0.654983</td>\n",
       "      <td>1.225248</td>\n",
       "      <td>0.949292</td>\n",
       "      <td>-0.517774</td>\n",
       "      <td>2.862515</td>\n",
       "      <td>-1.070066</td>\n",
       "      <td>1.372537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>534055 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        M_SESSION_UID  M_SESSION_TIME  M_FRAME_IDENTIFIER  M_PLAYER_CAR_INDEX  \\\n",
       "0           -0.941930       -0.907981           -0.958823            0.481238   \n",
       "1           -0.941930       -0.907981           -0.958823            0.481238   \n",
       "2           -0.941930       -0.907981           -0.958823            0.481238   \n",
       "3           -0.941930       -0.907981           -0.958823            0.481238   \n",
       "4           -0.941930       -0.907981           -0.958823            0.481238   \n",
       "...               ...             ...                 ...                 ...   \n",
       "534050       2.209103       -0.928847           -0.981442           -2.199539   \n",
       "534051       2.209103       -0.928847           -0.981442           -2.199539   \n",
       "534052       2.209103       -0.928847           -0.981442           -2.199539   \n",
       "534053       2.209103       -0.928847           -0.981442           -2.199539   \n",
       "534054       2.209103       -0.928847           -0.981442           -2.199539   \n",
       "\n",
       "        M_SESSION_LINK_IDENTIFIER  M_TRACK_TEMPERATURE  M_TRACK_LENGTH  \\\n",
       "0                       -0.834546            -0.185343       -1.821453   \n",
       "1                       -0.834546            -0.185343       -1.821453   \n",
       "2                       -0.834546            -0.185343       -1.821453   \n",
       "3                       -0.834546            -0.185343       -1.821453   \n",
       "4                       -0.834546            -0.185343       -1.821453   \n",
       "...                           ...                  ...             ...   \n",
       "534050                   1.230293            -1.901298        0.544278   \n",
       "534051                   1.230293            -1.901298        0.544278   \n",
       "534052                   1.230293            -1.901298        0.544278   \n",
       "534053                   1.230293            -1.901298        0.544278   \n",
       "534054                   1.230293            -1.901298        0.544278   \n",
       "\n",
       "        M_AIR_TEMPERATURE  M_TRACK_ID  M_TIME_OFFSET  M_RAIN_PERCENTAGE  \\\n",
       "0               -0.390822    1.745594      -0.918268          -0.320525   \n",
       "1               -0.390822    1.745594      -0.918268          -0.320525   \n",
       "2               -0.390822    1.745594      -0.723403          -0.320525   \n",
       "3               -0.390822    1.745594      -0.723403          -0.320525   \n",
       "4               -0.390822    1.745594      -0.528538          -0.320525   \n",
       "...                   ...         ...            ...                ...   \n",
       "534050          -2.205470   -0.654983      -0.723403           1.130695   \n",
       "534051          -2.205470   -0.654983      -0.528538           0.767890   \n",
       "534052          -2.205470   -0.654983       0.056057          -0.139123   \n",
       "534053          -2.205470   -0.654983       0.640653          -0.139123   \n",
       "534054          -2.205470   -0.654983       1.225248           0.949292   \n",
       "\n",
       "        M_AI_DIFFICULTY  M_NUM_MARSHAL_ZONES  M_SESSION_TIME_SPENT  M_WEATHER  \n",
       "0              1.701675            -1.353735             -0.227546  -0.627758  \n",
       "1              1.701675            -1.353735             -0.227546  -0.627758  \n",
       "2              1.701675            -1.353735             -0.227546  -0.627758  \n",
       "3              1.701675            -1.353735             -0.227546  -0.627758  \n",
       "4              1.701675            -1.353735             -0.227546  -0.627758  \n",
       "...                 ...                  ...                   ...        ...  \n",
       "534050        -0.517774             2.862515             -1.070066   1.372537  \n",
       "534051        -0.517774             2.862515             -1.070066   1.372537  \n",
       "534052        -0.517774             2.862515             -1.070066   1.372537  \n",
       "534053        -0.517774             2.862515             -1.070066   1.372537  \n",
       "534054        -0.517774             2.862515             -1.070066   1.372537  \n",
       "\n",
       "[534055 rows x 15 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "pd.DataFrame(scaler.fit_transform(final_data_weather), columns = final_data_weather.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f605cc3f",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h4><b>2. Model Experimentations I: Weather Classification</b></h4>\n",
    "Here are the 4 classification algorithms we will experiment with:\n",
    "\n",
    "- Gradient Boosted Trees Classifier\n",
    "- XGBoost Classifier\n",
    "- Light Gradient Boosted Machines Classifier\n",
    "- RandomForest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38df2a66",
   "metadata": {},
   "source": [
    "\n",
    "##### **(a) Gradient Boosted Trees Classifier**\n",
    "\n",
    "*First Experiment: Without Standardisation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0365b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd174933",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-519525b621a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_gbc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGBC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel_gbc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-558a011926ca>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(X_train, y_train, model)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mn_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mlog_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/generalmachinelearningforgpusonpython3_7vy/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0msample_weight_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0mbegin_at_stage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m             \u001b[0mmonitor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m         )\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/generalmachinelearningforgpusonpython3_7vy/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    670\u001b[0m                 \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mX_csc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                 \u001b[0mX_csr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m             )\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/generalmachinelearningforgpusonpython3_7vy/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             residual = loss.negative_gradient(\n\u001b[0;32m--> 223\u001b[0;31m                 \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions_copy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m             )\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/generalmachinelearningforgpusonpython3_7vy/lib/python3.7/site-packages/sklearn/ensemble/_gb_losses.py\u001b[0m in \u001b[0;36mnegative_gradient\u001b[0;34m(self, y, raw_predictions, k, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \"\"\"\n\u001b[1;32m    822\u001b[0m         return y - np.nan_to_num(\n\u001b[0;32m--> 823\u001b[0;31m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_predictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m         )\n\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/generalmachinelearningforgpusonpython3_7vy/lib/python3.7/site-packages/scipy/special/_logsumexp.py\u001b[0m in \u001b[0;36mlogsumexp\u001b[0;34m(a, axis, b, keepdims, return_sign)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0ma_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0ma_max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/conda/generalmachinelearningforgpusonpython3_7vy/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2704\u001b[0m     \"\"\"\n\u001b[1;32m   2705\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0;32m-> 2706\u001b[0;31m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/generalmachinelearningforgpusonpython3_7vy/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_gbc = training(X_train, y_train, GBC)\n",
    "model_gbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1f1831",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gb_accuracy = model_gbc.accuracy\n",
    "model_gb_logloss = model_gbc.logloss\n",
    "model_gb_logloss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bdb4c3",
   "metadata": {},
   "source": [
    "*Second Experiment: With Standardisation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630ea7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC2 = GradientBoostingClassifier()\n",
    "model_gbc_scaled = scale_pipe(GBC2, X_train, y_train)\n",
    "model_gbc_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c043d373",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Fold 1 the Accuracy is 1.0, and the LogLoss is 0.0025856786731771144\n",
      "For Fold 2 the Accuracy is 1.0, and the LogLoss is 0.0022258996481037564\n",
      "For Fold 3 the Accuracy is 1.0, and the LogLoss is 0.0022946443723346334\n",
      "For Fold 4 the Accuracy is 1.0, and the LogLoss is 0.0021741248483805337\n",
      "For Fold 5 the Accuracy is 1.0, and the LogLoss is 0.0022748596871658266\n",
      "For Fold 6 the Accuracy is 1.0, and the LogLoss is 0.0025054619903956393\n",
      "For Fold 7 the Accuracy is 1.0, and the LogLoss is 0.0024137793942517354\n",
      "For Fold 8 the Accuracy is 1.0, and the LogLoss is 0.0022935201711755965\n",
      "For Fold 9 the Accuracy is 1.0, and the LogLoss is 0.002422249096510743\n",
      "For Fold 10 the Accuracy is 1.0, and the LogLoss is 0.002341781701161599\n",
      "For Fold 11 the Accuracy is 1.0, and the LogLoss is 0.002391817244708867\n",
      "For Fold 12 the Accuracy is 1.0, and the LogLoss is 0.002379902752678636\n",
      "For Fold 13 the Accuracy is 1.0, and the LogLoss is 0.00226958303699276\n",
      "For Fold 14 the Accuracy is 1.0, and the LogLoss is 0.002290376835330036\n",
      "For Fold 15 the Accuracy is 1.0, and the LogLoss is 0.002469671533703149\n",
      "For Fold 16 the Accuracy is 1.0, and the LogLoss is 0.002358753144848917\n",
      "For Fold 17 the Accuracy is 1.0, and the LogLoss is 0.002550481139505275\n"
     ]
    }
   ],
   "source": [
    "#GBC2 = GradientBoostingClassifier()\n",
    "#model_gbc_scaled = scale_pipe(GBC2, X_train, y_train)\n",
    "#model_gbc_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c10890",
   "metadata": {},
   "source": [
    "##### **(b) XGBoost Classifier**\n",
    "\n",
    "*First Experiment: Without Standardisation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7cbaa1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4f86a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:19:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "For Fold 1, the Accuracy is 1.0, and the LogLoss is 6.595909427796833e-06\n",
      "[01:22:25] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "For Fold 2, the Accuracy is 1.0, and the LogLoss is 6.239530378252062e-06\n",
      "[01:25:07] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "For Fold 3, the Accuracy is 1.0, and the LogLoss is 6.334016523466604e-06\n",
      "[01:27:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "For Fold 4, the Accuracy is 1.0, and the LogLoss is 7.366365452343651e-06\n",
      "[01:30:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "For Fold 5, the Accuracy is 1.0, and the LogLoss is 6.633528435390757e-06\n",
      "[01:33:11] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "For Fold 6, the Accuracy is 1.0, and the LogLoss is 5.848046982227228e-06\n",
      "[01:36:20] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "For Fold 7, the Accuracy is 1.0, and the LogLoss is 6.650637248941316e-06\n",
      "[01:39:00] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "For Fold 8, the Accuracy is 1.0, and the LogLoss is 8.264812783209205e-06\n",
      "[01:41:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "model_xgb = training(X_train, y_train, xgb)\n",
    "model_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92cad8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb_accuracy = model_xgb.accuracy\n",
    "model_xgb_logloss = model_xgb.logloss\n",
    "model_xgb_logloss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0179e16",
   "metadata": {},
   "source": [
    "*Second Experiment: With Standardisation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16df4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC2 = GradientBoostingClassifier()\n",
    "model_xgb_scaled = scale_pipe(xgb, X_train, y_train)\n",
    "model_xgb_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0273f5",
   "metadata": {},
   "source": [
    "\n",
    "##### **(c) Light Gradient Boosted Machines Classifier**\n",
    "\n",
    "*First Experiment: Without Standardisation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be9cfb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a18839fe",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-519525b621a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_gbc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGBC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel_gbc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-558a011926ca>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(X_train, y_train, model)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mn_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mlog_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/generalmachinelearningforgpusonpython3_7vy/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0msample_weight_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0mbegin_at_stage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m             \u001b[0mmonitor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m         )\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/generalmachinelearningforgpusonpython3_7vy/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    670\u001b[0m                 \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mX_csc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                 \u001b[0mX_csr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m             )\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/generalmachinelearningforgpusonpython3_7vy/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             residual = loss.negative_gradient(\n\u001b[0;32m--> 223\u001b[0;31m                 \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions_copy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m             )\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/generalmachinelearningforgpusonpython3_7vy/lib/python3.7/site-packages/sklearn/ensemble/_gb_losses.py\u001b[0m in \u001b[0;36mnegative_gradient\u001b[0;34m(self, y, raw_predictions, k, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \"\"\"\n\u001b[1;32m    822\u001b[0m         return y - np.nan_to_num(\n\u001b[0;32m--> 823\u001b[0;31m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_predictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m         )\n\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/generalmachinelearningforgpusonpython3_7vy/lib/python3.7/site-packages/scipy/special/_logsumexp.py\u001b[0m in \u001b[0;36mlogsumexp\u001b[0;34m(a, axis, b, keepdims, return_sign)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0ma_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0ma_max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/conda/generalmachinelearningforgpusonpython3_7vy/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2704\u001b[0m     \"\"\"\n\u001b[1;32m   2705\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0;32m-> 2706\u001b[0;31m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/generalmachinelearningforgpusonpython3_7vy/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_lgb = training(X_train, y_train, lgb)\n",
    "model_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf0568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb_accuracy = model_lgb.accuracy\n",
    "model_lgb_logloss = model_lgb.logloss\n",
    "model_lgb_logloss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e6b192",
   "metadata": {},
   "source": [
    "*Second Experiment: With Standardisation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb46d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb2 = GradientBoostingClassifier()\n",
    "model_lgb_scaled = scale_pipe(lgb2, X_train, y_train)\n",
    "model_lgb_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceca484c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d8fd1a9",
   "metadata": {},
   "source": [
    "<br>\n",
    "<h4><b>2. Model Experimentations I: Classification</b></h4>\n",
    "Models we will experiment with:\n",
    "- XGBoost Cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0347ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:generalmachinelearningforgpusonpython3_7vy]",
   "language": "python",
   "name": "conda-env-generalmachinelearningforgpusonpython3_7vy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
